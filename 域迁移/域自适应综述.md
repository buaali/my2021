# [域自适应](https://blog.csdn.net/SHU15121856/article/details/106874558)

## 迁移学习的直观理解
* 把一个领域上学习的知识迁移到另一个领域上
  * 源域(Source Domain)
  * 源任务(Source Task)
  * 目标域(Target Domain)
  * 目标任务(Target Task)

## 迁移学习的种类
* [一篇2012年的综述](https://ieeexplore.ieee.org/abstract/document/5288526/)将迁移学习按照有标记的样本的情况分为三类
![](./迁移分类.png)

## 领域自适应简述
* Domain Adaptation是一种特殊的迁移学习
  * 源任务与目标任务相同
  * 源域和目标域的数据分布不同
  * 源域有大量的标记好的样本
  * 目标域没有（或只有少数）标记的样本、
* 样例对比图
![目标是同样的，但是数据分布有很大差别](./源域和目标域的分布样例.png "目标是同样的，但是数据分布有很大差别")
* 域自适应前后对比
![域自适应的效果](./域自适应效果.png "域自适应的效果")

## 域自适应的研究方向
* 多步域自适应（源域和目标域差距过大）
* 单步域自适应
  * 同质（Homogeneous，数据空间相同，数据分布不同）
  * 异质（Heterogeneous，数据空间都不同）
  
  同质或者异质的DA中又分别可以根据**目标域数据的打标签情况**分为**监督的、半监督的、无监督**的DA。
* 研究方向图示
![](./域自适应的研究方向.png "域自适应研究方向")

## 域自适应的方法
* 基于特征的自适应（Feature Adaptation）
  * 将源域样本和目标域样本用一个映射$\Phi$调整到同一个特征空间，这样在这个特征空间样本能够“对齐”
* 基于实例的自适应（Instance Adaptation）
  * 考虑到源域中总有一些样本和目标域样本很相似，那么就将源域的所有样本的Loss在训练时都乘以一个权重$w_i$（即表示“看重”的程度），和目标域越相似的样本，这个权重就越大
* 基于模型参数的自适应（Model Adaptation）
  * 找到新的参数$\theta'$通过参数的迁移使得模型能更好的在目标域上工作

如果目标域数据没有标签，就没法用Fine-Tune把目标域数据扔进去训练，这时候无监督的自适应方法就是基于特征的自适应。因为有很多能衡量源域和目标域数据的距离的数学公式，那么就能把距离计算出来嵌入到网络中作为Loss来训练，这样就能优化让这个距离逐渐变小，最终训练出来的模型就将源域和目标域就被放在一个足够近的特征空间里了。

这些衡量源域和目标域数据距离的数学公式有KL Divergence、MMD、H-divergence和Wasserstein distance等。
# [深度学习的域适应论文调研](https://blog.csdn.net/wangs1996/article/details/112862949?spm=1001.2014.3001.5502)
## Domain Adaptive Faster R-CNN for Object Detection in the Wild
[Paper in CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.pdf)\
[Code](https://github.com/krumo/Domain-Adaptive-Faster-RCNN-PyTorch)\
[Blog](https://cloud.tencent.com/developer/article/1631665)\
**数据集**
  * Cityscapes
  * KITTI
  * SIM10K

**Pipeline**\
![](./Domain%20Adaptive%20Faster%20R-CNN%20for%20Object%20Detection%20in%20the%20Wild.jpg)
**具体方法**\
主要贡献在三个方面，可以从Loss入手理解：
$$L = L_{det} + \lambda(L_{img} + L_{ins} + L_{cst})$$
*  $L_{det}$是检测部分的损失，$L_{det} = L_{rpn} + L_{roi}$
*  $L_{img}$是Pipeline的下分支，由Image-Level的分类器产生。这个分支的输入与RPN网络的输入相同，是backbone输出的特征图。目的是学习图片级的和域无关（域不变）特征。整个分支形成一个GAN（生成对抗网络）的训练方式，backbone对于每个Domain的图片尽可能输出相同的特征，而Image-Level分类器则尽可能识别出该特征属于哪个Domain（这部分具体由 **梯度反向层(GRL,gradient revere layer)** 实现，下文详细介绍）
*  $L_{ins}$是Pipeline的上分支，由Instance—Level的分类器产生。这个分支的输入是Faster-RCNN输出的实例（bounding box），目的是学习具体目标物的域不变特征，同样通过GRL实现对抗训练。
*  $L_{cst}$是一致性正则化损失，目的是约束图片级分支和实例级分支之间的信息差异以提取域不变信息。$L_{cst} = \Sigma_{i,j}{||\frac{1}{|I|}\Sigma_{u,v}{p_i^{(u,v)}} - p_{i,j}||_2}$
*  **梯度反向层(GRL, gradient revere layer)**，其目的是在最小化Instance/Image-level domain classifier loss的同时，优化基础网络，即分类器要尽力的分类出特征属于哪一个域，同时特征抽取的基础网络需要混淆两个域的特征，从而特征对齐。
   *  梯度反传层[Paper](https://arxiv.org/abs/1409.7495) [Blog1](https://zhuanlan.zhihu.com/p/50710267) [Blog2](https://zhuanlan.zhihu.com/p/109051269)
   *  梯度反转层主要同在特征提取器与域分类器之间，那么在反向传播过程中，域分类器的域分类损失的梯度反向传播到特征提取器的参数之前会自动取反，进而实现了类似与GAN的对抗损失







